{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1i3GCZ3WnHD6"
   },
   "source": [
    "# Twitter Data Stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKla1G99nLQC"
   },
   "source": [
    "## Install Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E9Q6omF3nBUv",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!pip install selenium google-cloud-bigquery pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tgr4Etr-nVWk"
   },
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6qVlf9xmnUgC"
   },
   "outputs": [],
   "source": [
    "# For accessing and parsing Twitter Webpages\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Structuring Collected Data\n",
    "import pandas as pd\n",
    "\n",
    "# General Libraries\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import os\n",
    "import requests\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGqJ81tvnpmJ"
   },
   "source": [
    "## Variable Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DitO1mjdnnZR"
   },
   "outputs": [],
   "source": [
    "# Twitter Handles to be scraped\n",
    "twitter_users = ['slickdeals', 'WHO', 'POTUS', 'backlon', 'instagram']\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'C:\\Users\\yashsri\\Desktop\\Twitter_Scraper\\Twitter Data Stream.json'\n",
    "bq_client = bigquery.Client()\n",
    "\n",
    "table_id = \"twitter-data-stream.twitter_data.twitter_data_values\"\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    autodetect=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scrape Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Tweet IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_tweet_ids(user):\n",
    "#Input: Twitter User Handle (String)\n",
    "#Output: (Twitter ID (String), DateTime (String))\n",
    "\n",
    "#Description: \n",
    "#- Initiate a Webdriver instance (Firefox here)\n",
    "#- Store unique ID,DateTime pairs in ids (Set)\n",
    "#- Load Twitter User page and added wait time for page load\n",
    "#- Finds all the \"a\" tags in the current browser with the status_format (String)\n",
    "#- Extracts datetime from the \"time\" tag\n",
    "#- The function collects the tweets for the current date.\n",
    "#- If date doesn't match with today's date, the flag becomes False and loop breaks.\n",
    "#- Else, the loop continues with page scrolling.\n",
    "\n",
    "#- Stale Element and Missing Tag errors are handled using try/except.    \n",
    "\n",
    "    browser = webdriver.Firefox(executable_path = 'geckodriver.exe')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    ids = set()\n",
    "    \n",
    "    status_format = \"https://twitter.com/\" + user + \"/status/\"\n",
    "\n",
    "    browser.get('https://twitter.com/' + user)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    flag = True\n",
    "\n",
    "    while flag:\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            a_tags = browser.find_elements_by_tag_name(\"a\")\n",
    "\n",
    "            for link in a_tags:\n",
    "\n",
    "                url = link.get_attribute('href')\n",
    "\n",
    "                if status_format in url:\n",
    "\n",
    "                    tweet_id = url.split(status_format)[1].split(\"/\")[0]\n",
    "                    dt = link.find_elements_by_tag_name(\"time\")\n",
    "                    \n",
    "                    if len(dt) > 0:\n",
    "                        dt = dt[0].get_attribute(\"datetime\")\n",
    "                        \n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "                    #print(datetime.datetime.strptime(dt.split(\"T\")[0], '%Y-%m-%d').date(), datetime.datetime.strptime('2021-02-25', '%Y-%m-%d').date(), datetime.datetime.strptime('2021-02-25', '%Y-%m-%d').date() != datetime.datetime.strptime(dt.split(\"T\")[0], '%Y-%m-%d').date())\n",
    "\n",
    "                    if datetime.datetime.strptime('2021-02-25', '%Y-%m-%d').date() != datetime.datetime.strptime(dt.split(\"T\")[0], '%Y-%m-%d').date():\n",
    "                        flag = False\n",
    "                        \n",
    "                    ids.add((tweet_id, dt))\n",
    "                        \n",
    "            browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "            \n",
    "        except Exception as error:\n",
    "            \n",
    "            print(error)\n",
    "            continue\n",
    "    \n",
    "    browser.quit()\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Tweet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_tweet_data(user, id):\n",
    "#Input: Twitter User Handle (String), Tweet ID (String)\n",
    "#Output: Tweet Data (Dictionary)\n",
    "\n",
    "#Description: \n",
    "#- Initiate a Webdriver instance (Firefox here)\n",
    "#- Store unique hashtags, urls, mentions (Set)\n",
    "#- Load Twitter User page and added wait time for page load\n",
    "#- Finds all the \"a\" tags in the current browser with the twitter shortening format (String)\n",
    "#- Extracts data from the \"span\" tag with specific characters to determine hashtags and mentions. \n",
    "\n",
    "#- Stale Element and Missing Tag errors are handled using try/except.\n",
    "    \n",
    "    browser = webdriver.Firefox(executable_path = 'geckodriver.exe')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    status_format = \"https://twitter.com/\" + user + \"/status/\"\n",
    "    \n",
    "    data = dict()\n",
    "    mentions = set()\n",
    "    urls = set()\n",
    "    hashtags = set()\n",
    "    \n",
    "    flag = True\n",
    "    \n",
    "    while flag:\n",
    "        \n",
    "        try:\n",
    "\n",
    "            browser.get(status_format + id[0])\n",
    "            time.sleep(5)\n",
    "\n",
    "            article = browser.find_element_by_tag_name(\"main\").find_element_by_tag_name(\"article\")\n",
    "\n",
    "            a_tags = article.find_elements_by_tag_name(\"a\")\n",
    "\n",
    "            for a in a_tags:\n",
    "\n",
    "                link = a.get_attribute('href')\n",
    "\n",
    "                if \"https://t.co\" in link:\n",
    "                    urls.add(link)\n",
    "\n",
    "            span_tags = article.find_elements_by_tag_name(\"span\")\n",
    "\n",
    "            body = ''\n",
    "            datetime = None\n",
    "\n",
    "            for span in span_tags[3:]:\n",
    "\n",
    "                text = span.text.strip()\n",
    "\n",
    "                if '@' in text:\n",
    "                    mentions.add(text)\n",
    "\n",
    "                if '#' in text:\n",
    "                    hashtags.add(text)\n",
    "\n",
    "                if 'Â·' in text:\n",
    "                    break\n",
    "\n",
    "                body += text + \" \"\n",
    "\n",
    "\n",
    "            data['mentions_list'] = str(list(mentions))\n",
    "            data['urls_list'] = str(list(urls))\n",
    "            data['hashtags_list'] = str(list(hashtags))\n",
    "            data['tweet_id'] = id[0]\n",
    "            data['username'] = user\n",
    "            data['date'] = id[1].split(\"T\")[0].strip()\n",
    "            data['time'] = id[1].split(\"T\")[1].split(\".\")[0]\n",
    "            data['tweet_body'] = body.strip()\n",
    "            \n",
    "            flag = False\n",
    "            \n",
    "        except Exception as error:\n",
    "            \n",
    "            print(error)\n",
    "            continue\n",
    "    \n",
    "    browser.quit()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Twitter User Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "\n",
    "for user in twitter_users:\n",
    "    \n",
    "    ids = scrape_tweet_ids(user)\n",
    "    \n",
    "    for id in ids:\n",
    "        data = data.append(scrape_tweet_data(user, id), ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save DataFrame to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = bq_client.load_table_from_dataframe(\n",
    "    data, table_id, job_config=job_config\n",
    ")\n",
    "job.result()\n",
    "\n",
    "table = bq_client.get_table(table_id)\n",
    "print(\n",
    "    \"Loaded {} rows and {} columns to {}\".format(\n",
    "        table.num_rows, len(table.schema), table_id\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "YKla1G99nLQC",
    "Tgr4Etr-nVWk",
    "OxYowFXxnjEP"
   ],
   "name": "Twitter-Data-Stream.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
